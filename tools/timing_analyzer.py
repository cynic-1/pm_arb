#!/usr/bin/env python3
"""
å»¶è¿Ÿç»Ÿè®¡åˆ†æå·¥å…·

ç”¨äºåˆ†æå¥—åˆ©ç¨‹åºçš„æ—¶é—´æµ‹é‡æ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨
"""

import argparse
import sys
import json
from pathlib import Path
from typing import List, Dict, Any
from collections import defaultdict
import statistics

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from arbitrage_core.timing import get_timing_tracker, get_token_bucket_monitor


def analyze_timing_data():
    """åˆ†ææ—¶é—´æµ‹é‡æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"""
    tracker = get_timing_tracker()
    tb_monitor = get_token_bucket_monitor()

    sessions = tracker.get_all_sessions()

    if not sessions:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ—¶é—´æµ‹é‡æ•°æ®")
        return

    print(f"\n{'='*80}")
    print(f"â±ï¸  å¥—åˆ©ç¨‹åºå»¶è¿Ÿåˆ†ææŠ¥å‘Š")
    print(f"{'='*80}\n")

    # åŸºæœ¬ç»Ÿè®¡
    total_sessions = len(sessions)
    successful_sessions = [s for s in sessions if s.success]
    failed_sessions = [s for s in sessions if not s.success]

    success_rate = len(successful_sessions) / total_sessions * 100 if total_sessions > 0 else 0

    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  - æ€»æ‰§è¡Œæ¬¡æ•°: {total_sessions}")
    print(f"  - æˆåŠŸæ¬¡æ•°: {len(successful_sessions)} ({len(successful_sessions)/total_sessions*100:.1f}%)")
    print(f"  - å¤±è´¥æ¬¡æ•°: {len(failed_sessions)} ({len(failed_sessions)/total_sessions*100:.1f}%)")
    print(f"  - æˆåŠŸç‡: {success_rate:.2f}%\n")

    # æ€»è€—æ—¶ç»Ÿè®¡
    all_elapsed_times = [s.total_elapsed for s in sessions]
    success_elapsed_times = [s.total_elapsed for s in successful_sessions]
    failed_elapsed_times = [s.total_elapsed for s in failed_sessions]

    threshold_150ms = 150.0
    within_threshold = len([t for t in all_elapsed_times if t < threshold_150ms])
    within_threshold_rate = within_threshold / len(all_elapsed_times) * 100 if all_elapsed_times else 0

    print(f"â±ï¸  æ€»è€—æ—¶ç»Ÿè®¡:")
    print(f"  å…¨éƒ¨æ‰§è¡Œ:")
    print(f"    - å¹³å‡: {statistics.mean(all_elapsed_times):.2f}ms")
    print(f"    - ä¸­ä½æ•°: {statistics.median(all_elapsed_times):.2f}ms")
    print(f"    - æœ€å°: {min(all_elapsed_times):.2f}ms")
    print(f"    - æœ€å¤§: {max(all_elapsed_times):.2f}ms")
    print(f"    - æ ‡å‡†å·®: {statistics.stdev(all_elapsed_times):.2f}ms" if len(all_elapsed_times) > 1 else "    - æ ‡å‡†å·®: N/A")
    print(f"    - <150msæ¬¡æ•°: {within_threshold}/{len(all_elapsed_times)} ({within_threshold_rate:.1f}%)")

    if success_elapsed_times:
        print(f"\n  æˆåŠŸæ‰§è¡Œ:")
        print(f"    - å¹³å‡: {statistics.mean(success_elapsed_times):.2f}ms")
        print(f"    - ä¸­ä½æ•°: {statistics.median(success_elapsed_times):.2f}ms")
        print(f"    - æœ€å°: {min(success_elapsed_times):.2f}ms")
        print(f"    - æœ€å¤§: {max(success_elapsed_times):.2f}ms")

    if failed_elapsed_times:
        print(f"\n  å¤±è´¥æ‰§è¡Œ:")
        print(f"    - å¹³å‡: {statistics.mean(failed_elapsed_times):.2f}ms")
        print(f"    - ä¸­ä½æ•°: {statistics.median(failed_elapsed_times):.2f}ms")
        print(f"    - æœ€å°: {min(failed_elapsed_times):.2f}ms")
        print(f"    - æœ€å¤§: {max(failed_elapsed_times):.2f}ms")

    # å„é˜¶æ®µè€—æ—¶ç»Ÿè®¡
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ å„é˜¶æ®µè€—æ—¶è¯¦ç»†åˆ†æ:")
    print(f"{'='*80}\n")

    stage_times = defaultdict(list)
    for session in sessions:
        for point in session.points:
            stage_times[point.name].append(point.delta_from_previous)

    # æŒ‰åç§°æ’åºå¹¶è¾“å‡º
    for stage_name in sorted(stage_times.keys()):
        times = stage_times[stage_name]
        if not times:
            continue

        print(f"  {stage_name}:")
        print(f"    - æ¬¡æ•°: {len(times)}")
        print(f"    - å¹³å‡: {statistics.mean(times):.2f}ms")
        print(f"    - ä¸­ä½æ•°: {statistics.median(times):.2f}ms")
        print(f"    - æœ€å°: {min(times):.2f}ms")
        print(f"    - æœ€å¤§: {max(times):.2f}ms")
        if len(times) > 1:
            print(f"    - æ ‡å‡†å·®: {statistics.stdev(times):.2f}ms")
            # P95
            sorted_times = sorted(times)
            p95_index = int(len(sorted_times) * 0.95)
            print(f"    - P95: {sorted_times[p95_index]:.2f}ms")
        print()

    # Token Bucketç»Ÿè®¡
    print(f"{'='*80}")
    print(f"ğŸª£ Token Bucket ç»Ÿè®¡:")
    print(f"{'='*80}\n")

    tb_stats = tb_monitor.get_statistics()
    if tb_stats['total_requests'] > 0:
        print(f"  - æ€»è¯·æ±‚æ•°: {tb_stats['total_requests']}")
        print(f"  - é˜»å¡æ¬¡æ•°: {tb_stats['blocked_count']}")
        print(f"  - é˜»å¡ç‡: {tb_stats['blocked_rate']*100:.2f}%")

        if 'mean_wait_time' in tb_stats:
            print(f"  - å¹³å‡ç­‰å¾…: {tb_stats['mean_wait_time']:.2f}ms")
            print(f"  - ä¸­ä½æ•°ç­‰å¾…: {tb_stats['median_wait_time']:.2f}ms")
            print(f"  - æœ€å¤§ç­‰å¾…: {tb_stats['max_wait_time']:.2f}ms")
            print(f"  - P95ç­‰å¾…: {tb_stats['p95_wait_time']:.2f}ms")
    else:
        print("  æš‚æ— Token Bucketç»Ÿè®¡æ•°æ®")

    # æˆåŠŸvså¤±è´¥çš„å¯¹æ¯”åˆ†æ
    if successful_sessions and failed_sessions:
        print(f"\n{'='*80}")
        print(f"ğŸ” æˆåŠŸ vs å¤±è´¥ å¯¹æ¯”åˆ†æ:")
        print(f"{'='*80}\n")

        # å¯¹æ¯”å„é˜¶æ®µè€—æ—¶
        success_stage_times = defaultdict(list)
        failed_stage_times = defaultdict(list)

        for session in successful_sessions:
            for point in session.points:
                success_stage_times[point.name].append(point.delta_from_previous)

        for session in failed_sessions:
            for point in session.points:
                failed_stage_times[point.name].append(point.delta_from_previous)

        # æ‰¾å‡ºå·®å¼‚æœ€å¤§çš„é˜¶æ®µ
        all_stages = set(success_stage_times.keys()) | set(failed_stage_times.keys())

        for stage_name in sorted(all_stages):
            if stage_name not in success_stage_times or stage_name not in failed_stage_times:
                continue

            success_avg = statistics.mean(success_stage_times[stage_name])
            failed_avg = statistics.mean(failed_stage_times[stage_name])
            diff = failed_avg - success_avg
            diff_pct = (diff / success_avg * 100) if success_avg > 0 else 0

            if abs(diff) > 5:  # åªæ˜¾ç¤ºå·®å¼‚å¤§äº5msçš„é˜¶æ®µ
                print(f"  {stage_name}:")
                print(f"    - æˆåŠŸå¹³å‡: {success_avg:.2f}ms")
                print(f"    - å¤±è´¥å¹³å‡: {failed_avg:.2f}ms")
                print(f"    - å·®å¼‚: {diff:+.2f}ms ({diff_pct:+.1f}%)")
                if abs(diff_pct) > 50:
                    print(f"    âš ï¸  è¯¥é˜¶æ®µå¯èƒ½æ˜¯å¤±è´¥çš„ä¸»è¦åŸå› !")
                print()

    # ç“¶é¢ˆè¯†åˆ«
    print(f"{'='*80}")
    print(f"ğŸ¯ æ€§èƒ½ç“¶é¢ˆè¯†åˆ«:")
    print(f"{'='*80}\n")

    # æ‰¾å‡ºè€—æ—¶æœ€å¤šçš„3ä¸ªé˜¶æ®µ
    avg_stage_times = {
        name: statistics.mean(times)
        for name, times in stage_times.items()
    }
    sorted_stages = sorted(avg_stage_times.items(), key=lambda x: x[1], reverse=True)

    print("  è€—æ—¶æœ€é•¿çš„3ä¸ªé˜¶æ®µ:")
    for i, (stage_name, avg_time) in enumerate(sorted_stages[:3], 1):
        pct_of_total = (avg_time / statistics.mean(all_elapsed_times) * 100) if all_elapsed_times else 0
        print(f"    {i}. {stage_name}: {avg_time:.2f}ms (å æ¯” {pct_of_total:.1f}%)")

    print(f"\n{'='*80}")
    print(f"ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    print(f"{'='*80}\n")

    # æ ¹æ®æ•°æ®ç»™å‡ºä¼˜åŒ–å»ºè®®
    if within_threshold_rate < 50:
        print("  âš ï¸  å½“å‰åªæœ‰ {:.1f}% çš„æ‰§è¡Œåœ¨150mså†…å®Œæˆï¼Œå»ºè®®ä¼˜å…ˆä¼˜åŒ–:".format(within_threshold_rate))
        for stage_name, avg_time in sorted_stages[:3]:
            if avg_time > 20:
                print(f"    - ä¼˜åŒ– {stage_name} (å½“å‰å¹³å‡ {avg_time:.2f}ms)")

    if tb_stats['total_requests'] > 0 and tb_stats['blocked_rate'] > 0.2:
        print(f"  âš ï¸  Token Bucketé˜»å¡ç‡è¿‡é«˜ ({tb_stats['blocked_rate']*100:.1f}%)")
        print(f"    å»ºè®®: æå‡ OPINION_MAX_RPS é…ç½®")

    if 'mean_wait_time' in tb_stats and tb_stats['mean_wait_time'] > 100:
        print(f"  âš ï¸  Token Bucketå¹³å‡ç­‰å¾…æ—¶é—´è¿‡é•¿ ({tb_stats['mean_wait_time']:.2f}ms)")
        print(f"    å»ºè®®: å¢åŠ ä»¤ç‰Œæ¡¶å®¹é‡æˆ–æå‡è¡¥å……é€Ÿç‡")

    print(f"\n{'='*80}\n")


def export_json(output_file: str):
    """å¯¼å‡ºJSONæ ¼å¼çš„ç»Ÿè®¡æ•°æ®"""
    tracker = get_timing_tracker()
    tb_monitor = get_token_bucket_monitor()

    data = {
        "sessions": [],
        "statistics": tracker.get_statistics(),
        "token_bucket": tb_monitor.get_statistics()
    }

    for session in tracker.get_all_sessions():
        session_data = {
            "session_id": session.session_id,
            "start_time": session.start_time,
            "total_elapsed": session.total_elapsed,
            "success": session.success,
            "metadata": session.metadata,
            "points": [
                {
                    "name": p.name,
                    "timestamp": p.timestamp,
                    "elapsed_from_start": p.elapsed_from_start,
                    "delta_from_previous": p.delta_from_previous
                }
                for p in session.points
            ]
        }
        data["sessions"].append(session_data)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"âœ… æ•°æ®å·²å¯¼å‡ºåˆ°: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description="åˆ†æå¥—åˆ©ç¨‹åºçš„å»¶è¿Ÿæ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "--export-json",
        metavar="FILE",
        help="å¯¼å‡ºJSONæ ¼å¼çš„ç»Ÿè®¡æ•°æ®åˆ°æŒ‡å®šæ–‡ä»¶"
    )

    args = parser.parse_args()

    if args.export_json:
        export_json(args.export_json)
    else:
        analyze_timing_data()


if __name__ == "__main__":
    main()
