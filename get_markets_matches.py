"""
è·¨å¹³å°å¸‚åœºåŒ¹é…å·¥å…· - Opinion vs Polymarket
è¯¥æ¨¡å—ä»…ä¿ç•™å¸‚åœºåŒ¹é…ä¸ç»“æœä¿å­˜é€»è¾‘ã€‚
"""

import argparse
import json
import sys
import time
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List, Optional, Tuple
# Opinion SDK
from opinion_clob_sdk import Client as OpinionClient
from opinion_clob_sdk.model import TopicStatusFilter, TopicType
# Polymarket SDK
from py_clob_client.client import ClobClient
import requests
from py_clob_client.clob_types import ApiCreds

import requests
import os
from dotenv import load_dotenv
load_dotenv()


@dataclass
class MarketMatch:
    """åŒ¹é…çš„å¸‚åœºå¯¹"""
    question: str  # å¸‚åœºé—®é¢˜

    # Opinion å¸‚åœºä¿¡æ¯
    opinion_market_id: int
    opinion_yes_token: str
    opinion_no_token: str

    # Polymarket å¸‚åœºä¿¡æ¯
    polymarket_condition_id: str
    polymarket_yes_token: str
    polymarket_no_token: str
    polymarket_slug: str

    # ç›¸ä¼¼åº¦åˆ†æ•°
    similarity_score: float = 1.0

    # æˆªæ­¢æ—¶é—´ï¼ˆç§’çº§æ—¶é—´æˆ³ï¼‰
    cutoff_at: Optional[int] = None

    op_rules: Optional[str] = None  # Opinion å¸‚åœºè§„åˆ™
    poly_rules: Optional[str] = None  # Polymarket å¸‚åœºè§„åˆ™

    polymarket_neg_risk: Optional[bool] = False  # Polymarket neg_risk æ ‡å¿—


class CrossPlatformArbitrage:
    """è´Ÿè´£å¸‚åœºåŒ¹é…å’Œç»“æœä¿å­˜çš„ç²¾ç®€ç±»"""

    def __init__(
        self,
        gamma_api: str = "https://gamma-api.polymarket.com",
        unmatched_output_file: str = "unmatched_markets.json",
    ):
        self.gamma_api = gamma_api
        self.unmatched_output_file = unmatched_output_file
        self.opinion_markets: List[Dict] = []
        self.market_matches: List[MarketMatch] = []
        # Opinion å®¢æˆ·ç«¯
        print("ğŸ”§ åˆå§‹åŒ– Opinion å®¢æˆ·ç«¯...")
        self.opinion_client = OpinionClient(
            host=os.getenv('OP_HOST', 'https://proxy.opinion.trade:8443'),
            apikey=os.getenv('OP_API_KEY'),
            chain_id=int(os.getenv('OP_CHAIN_ID', '56')),
            rpc_url=os.getenv('OP_RPC_URL'),
            private_key=os.getenv('OP_PRIVATE_KEY'),
            multi_sig_addr=os.getenv('OP_MULTI_SIG_ADDRESS'),
        )
        
        # Polymarket å®¢æˆ·ç«¯ï¼ˆå‚è€ƒ place_order.pyï¼‰
        print("ğŸ”§ åˆå§‹åŒ– Polymarket å®¢æˆ·ç«¯...")
        HOST = "https://clob.polymarket.com"
        CHAIN_ID = 137
        PRIVATE_KEY = os.getenv("PM_KEY")
        FUNDER = os.getenv("PM_FUNDER")
        
        if PRIVATE_KEY:
            self.polymarket_client = ClobClient(
                HOST,
                key=PRIVATE_KEY,
                chain_id=CHAIN_ID,
                signature_type=2,
                funder=FUNDER
            )
            self.polymarket_client.set_api_creds(
                self.polymarket_client.create_or_derive_api_creds()
            )
        else:
            # åªè¯»æ¨¡å¼
            self.polymarket_client = ClobClient(HOST)
            print("READ-ONLY MODE: Polymarket client initialized without private key.\n")

    def fetch_opinion_markets(self, max_markets: int = 200, topic_type: TopicType = TopicType.BINARY) -> List[Dict]:
        """
        è·å– Opinion çš„æ‰€æœ‰æ´»è·ƒå¸‚åœº
        
        Args:
            max_markets: æœ€å¤§å¸‚åœºæ•°é‡
            topic_type: å¸‚åœºç±»å‹ (TopicType.BINARY æˆ– TopicType.CATEGORICAL)
        """
        print(f"ğŸ“Š è·å– Opinion å¸‚åœº (ç±»å‹: {topic_type})...")
        
        all_markets = []
        page = 1
        limit = 20  # Opinion API é™åˆ¶æ¯é¡µæœ€å¤š 20 æ¡
        father_count = 0
        
        while father_count < max_markets:
            response = self.opinion_client.get_markets(
                page=page,
                limit=limit,
                status=TopicStatusFilter.ACTIVATED,
                topic_type=topic_type
            )

            if response.errno != 0:
                print(f"âŒ è·å–å¤±è´¥: {response.errmsg}")
                break
            
            markets = response.result.list
            if not markets:
                print("âŒ æ— æ›´å¤šå¸‚åœºå¯è·å–")
                break

            print(f"  è·å–{len(markets)} ä¸ªå¸‚åœº")
            father_count += len(markets)

            # æ‰“å°ç¬¬ä¸€ä¸ªå¸‚åœºçš„æ•°æ®ç»“æ„ä»¥ä¾›è°ƒè¯•
            if page == 1 and len(markets) > 0:
                print("\n=== Opinion Market æ•°æ®ç»“æ„ç¤ºä¾‹ ===")
                first_market = markets[0]
                print(f"Market ID: {first_market.market_id}")
                print(f"Title: {first_market.market_title}")
                print(f"Available attributes: {dir(first_market)}")
                # å°è¯•è·å– rules å­—æ®µ
                rules = getattr(first_market, 'rules', None)
                print(f"Rules field: {rules}")
                print("=" * 50 + "\n")

            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            for market in markets:
                # æ£€æŸ¥æ˜¯å¦ä¸º CATEGORICAL ç±»å‹ä¸”æœ‰å­å¸‚åœº
                child_markets = getattr(market, 'child_markets', None)
                cutoff_raw = getattr(market, "cutoff_at", None)
                cutoff_ts = int(cutoff_raw) if cutoff_raw is not None else None

                if child_markets and len(child_markets) > 0:
                    # CATEGORICAL ç±»å‹: å±•å¹³å­å¸‚åœº
                    parent_title = market.market_title
                    parent_rules = getattr(market, 'rules', None) or ""
                    for child in child_markets:
                        if child.status_enum != 'Activated':
                            continue
                        # æ‹¼æ¥æ ‡é¢˜: "çˆ¶æ ‡é¢˜ - å­æ ‡é¢˜"
                        combined_title = f"{parent_title} - {child.market_title}"
                        # å­å¸‚åœºå¯èƒ½æœ‰è‡ªå·±çš„ rulesï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨çˆ¶å¸‚åœºçš„
                        child_rules = getattr(child, 'rules', None) or parent_rules

                        all_markets.append({
                            'market_id': child.market_id,
                            'title': combined_title,
                            'yes_token_id': getattr(child, 'yes_token_id', None),
                            'no_token_id': getattr(child, 'no_token_id', None),
                            'volume': float(getattr(child, 'volume', 0)),
                            'status': child.status,
                            'parent_market_id': market.market_id,
                            'parent_title': parent_title,
                            'child_title': child.market_title,
                            'cutoff_at': cutoff_ts,
                            'rules': child_rules
                        })
                else:
                    # BINARY ç±»å‹æˆ–æ— å­å¸‚åœº: ç›´æ¥æ·»åŠ 
                    market_rules = getattr(market, 'rules', None) or ""
                    all_markets.append({
                        'market_id': market.market_id,
                        'title': market.market_title,
                        'yes_token_id': getattr(market, 'yes_token_id', None),
                        'no_token_id': getattr(market, 'no_token_id', None),
                        'volume': float(getattr(market, 'volume', 0)),
                        'status': market.status,
                        'cutoff_at': cutoff_ts,
                        'rules': market_rules
                    })

            page += 1
        
        self.opinion_markets = all_markets
        print(f"âœ… è·å–åˆ° {len(all_markets)} ä¸ª Opinion å¸‚åœº\n")
        return all_markets

    def __fetch_opinion_markets(self, max_markets: int = 100, topic_type: TopicType = TopicType.BINARY) -> List[Dict]:
        """è·å– Opinion çš„æ‰€æœ‰æ´»è·ƒå¸‚åœº"""
        print("ğŸ“Š è·å– Opinion å¸‚åœº...")

        all_markets: List[Dict] = []
        page = 1
        limit = 20  # Opinion API é™åˆ¶æ¯é¡µæœ€å¤š 20 æ¡

        while len(all_markets) < max_markets:
            response = self.opinion_client.get_markets(
                page=page,
                limit=limit,
                status=TopicStatusFilter.ACTIVATED,
                topic_type=topic_type
            )

            if response.errno != 0:
                print(f"âŒ è·å–å¤±è´¥: {response.errmsg}")
                break

            markets = response.result.list
            if not markets:
                print("âŒ æ— æ›´å¤šå¸‚åœºå¯è·å–")
                break
            print(f"  è·å–åˆ° {len(markets)} ä¸ªå¸‚åœº (ç¬¬ {page} é¡µ)")
            print(f"  ç´¯è®¡å¸‚åœºæ•°: {len(all_markets) + len(markets)}")

            for market in markets:
                cutoff_raw = getattr(market, "cutoff_at", None)
                cutoff_ts = int(cutoff_raw) if cutoff_raw is not None else None

                child_markets = getattr(market, "child_markets", None)
                if child_markets:
                    parent_title = market.market_title
                    for child in child_markets:
                        # ç»§æ‰¿çˆ¶å¸‚åœºçš„æˆªæ­¢æ—¶é—´
                        entry = {
                            "market_id": child.market_id,
                            "title": f"{parent_title} - {child.market_title}",
                            "yes_token_id": getattr(child, "yes_token_id", None),
                            "no_token_id": getattr(child, "no_token_id", None),
                            "volume": getattr(child, "volume", 0),
                            "status": child.status,
                            "parent_market_id": market.market_id,
                            "parent_title": parent_title,
                            "child_title": child.market_title,
                            "cutoff_at": cutoff_ts,
                        }
                        all_markets.append(entry)
                        if len(all_markets) >= max_markets:
                            break
                else:
                    all_markets.append({
                        "market_id": market.market_id,
                        "title": market.market_title,
                        "yes_token_id": getattr(market, "yes_token_id", None),
                        "no_token_id": getattr(market, "no_token_id", None),
                        "volume": getattr(market, "volume", 0),
                        "status": market.status,
                        "cutoff_at": cutoff_ts,
                    })

            if len(all_markets) >= max_markets:
                break

            page += 1

        self.opinion_markets = all_markets
        print(f"âœ… è·å–åˆ° {len(all_markets)} ä¸ª Opinion å¸‚åœº\n")
        return all_markets

    # ==================== æœç´¢è¾…åŠ© ====================

    def search_polymarket_market(self, query: str, debug: bool = False) -> Optional[Dict]:
        """æ ¹æ®é—®é¢˜æ ‡é¢˜åœ¨ Polymarket æœç´¢åŒ¹é…å¸‚åœº"""
        try:
            response = requests.get(
                f"{self.gamma_api}/public-search",
                params={"q": query},
                timeout=10,
            )
            response.raise_for_status()
            results = response.json()

            events = results.get("events", [])
            if not events:
                return None

            # è·å–ç¬¬ä¸€ä¸ªäº‹ä»¶çš„æè¿°ä¿¡æ¯
            first_event = events[0]
            event_description = first_event.get("description", "")

            # è°ƒè¯•: æ‰“å°äº‹ä»¶æ•°æ®ç»“æ„
            if debug:
                print("\n=== Polymarket Event æ•°æ®ç»“æ„ç¤ºä¾‹ ===")
                print(f"Event ID: {first_event.get('id')}")
                print(f"Event Title: {first_event.get('title')}")
                print(f"Description: {event_description[:200] if event_description else 'None'}...")
                print(f"Available fields: {list(first_event.keys())}")
                print("=" * 50 + "\n")

            markets = first_event.get("markets", [])
            if not markets:
                return None

            if len(markets) == 1:
                return self._extract_market_entry(markets[0], event_description)

            best_match = None
            best_similarity = 0.0
            query_lower = query.lower().strip()

            for market in markets:
                market_question = market.get("question", "").lower().strip()
                similarity = self._calculate_similarity(query_lower, market_question)

                if similarity >= 0.95 or query_lower == market_question:
                    return self._extract_market_entry(market, event_description)

                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = market

            if best_match and best_similarity >= 0.6:
                return self._extract_market_entry(best_match, event_description)

            return None
        except Exception as exc:  # pragma: no cover - ä»…è®°å½•æ—¥å¿—
            print(f"  æœç´¢å¤±è´¥: {exc}")
            return None

    def _extract_market_entry(self, market: Dict, description: str = "") -> Optional[Dict]:
        token_ids_raw = market.get("clobTokenIds", "[]")
        token_ids = json.loads(token_ids_raw) if isinstance(token_ids_raw, str) else token_ids_raw
        if len(token_ids) < 2:
            return None
        return {
            "condition_id": market.get("conditionId"),
            "question": market.get("question"),
            "slug": market.get("slug"),
            "yes_token_id": token_ids[0],
            "no_token_id": token_ids[1],
            "volume": float(market.get("volume", 0)),
            "active": market.get("active", True),
            "description": description,  # æ·»åŠ äº‹ä»¶æè¿°
            "neg_risk": market.get("negRisk", False),  # æ·»åŠ  neg_risk æ ‡å¿—
        }

    # ==================== å¸‚åœºåŒ¹é… ====================

    def match_markets_by_search(self, topic_types: Optional[List[str]] = None) -> List[MarketMatch]:
        """ä½¿ç”¨æœç´¢ API åŒ¹é…ä¸¤ä¸ªå¹³å°çš„å¸‚åœº"""
        normalized_topics = {
            (topic or "BINARY").upper()
            for topic in (topic_types if topic_types else ["BINARY"])
        }
        invalid = normalized_topics.difference({"BINARY", "CATEGORICAL"})
        if invalid:
            raise ValueError(
                f"topic_type ä»…æ”¯æŒ BINARY/CATEGORICALï¼Œæ”¶åˆ°: {', '.join(sorted(invalid))}"
            )

        print(f"ğŸ” ä½¿ç”¨æœç´¢ API åŒ¹é…å¸‚åœº (ç±»å‹: {', '.join(sorted(normalized_topics))})...")

        matches: List[MarketMatch] = []
        unmatched_groups: List[Dict] = []

        binary_markets: List[Dict] = []
        categorical_groups: Dict[int, Dict] = {}

        for op_market in self.opinion_markets:
            if "parent_market_id" in op_market and "parent_title" in op_market:
                parent_id = op_market["parent_market_id"]
                if parent_id not in categorical_groups:
                    categorical_groups[parent_id] = {
                        "parent_title": op_market["parent_title"],
                        "children": [],
                    }
                categorical_groups[parent_id]["children"].append(op_market)
            else:
                binary_markets.append(op_market)

        process_binary = "BINARY" in normalized_topics
        process_categorical = "CATEGORICAL" in normalized_topics

        if process_binary:
            print(f"\nğŸ“Š å¤„ç† {len(binary_markets)} ä¸ª BINARY å¸‚åœº...")
            for i, op_market in enumerate(binary_markets, 1):
                op_title = op_market["title"]
                if "?" in op_title and not op_title.endswith("?"):
                    op_title = op_title.split("?", 1)[0] + "?"
                print(f"[{i}/{len(binary_markets)}] æœç´¢: {op_title[:60]}...")

                # åªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶å¯ç”¨è°ƒè¯•
                pm_market = self.search_polymarket_market(query=op_title, debug=(i == 1))

                if pm_market:
                    matches.append(
                        MarketMatch(
                            question=op_title,
                            opinion_market_id=op_market["market_id"],
                            opinion_yes_token=op_market.get("yes_token_id", "") or "",
                            opinion_no_token=op_market.get("no_token_id", "") or "",
                            cutoff_at=op_market.get("cutoff_at"),
                            polymarket_condition_id=pm_market["condition_id"],
                            polymarket_yes_token=pm_market["yes_token_id"],
                            polymarket_no_token=pm_market["no_token_id"],
                            polymarket_slug=pm_market["slug"],
                            similarity_score=1.0,
                            op_rules=op_market.get("rules", ""),
                            poly_rules=pm_market.get("description", ""),
                            polymarket_neg_risk=pm_market.get("neg_risk", False),  # æ·»åŠ  neg_risk
                        )
                    )
                    print("  âœ“ åŒ¹é…æˆåŠŸ")
                else:
                    print("  âœ— æœªæ‰¾åˆ°åŒ¹é…")

                time.sleep(1)

        if process_categorical:
            print(f"\nğŸ“Š å¤„ç† {len(categorical_groups)} ä¸ª CATEGORICAL å¸‚åœºç»„...")
            for group_idx, (parent_id, group_info) in enumerate(categorical_groups.items(), 1):
                parent_title = group_info["parent_title"]
                op_children = group_info["children"]
                if "?" in parent_title and not parent_title.endswith("?"):
                    parent_title = parent_title.split("?", 1)[0] + "?"

                print(f"\n[{group_idx}/{len(categorical_groups)}] çˆ¶å¸‚åœº: {parent_title}")
                print(f"  Opinion å­å¸‚åœºæ•°: {len(op_children)}")

                pm_children = self._fetch_polymarket_event_markets(parent_title)

                if not pm_children:
                    print("  âœ— æœªæ‰¾åˆ° Polymarket å¯¹åº”äº‹ä»¶")
                    unmatched_groups.append(
                        {
                            "parent_title": parent_title,
                            "opinion_children": [
                                {
                                    "market_id": child["market_id"],
                                    "child_title": child["child_title"],
                                    "yes_token_id": child.get("yes_token_id"),
                                    "no_token_id": child.get("no_token_id"),
                                }
                                for child in op_children
                            ],
                            "polymarket_children": [],
                        }
                    )
                    continue

                print(f"  Polymarket å­å¸‚åœºæ•°: {len(pm_children)}")
                matched, unmatched_op, unmatched_pm = self._match_child_markets(op_children, pm_children, parent_title)
                matches.extend(matched)

                if unmatched_op or unmatched_pm:
                    unmatched_groups.append(
                        {
                            "parent_title": parent_title,
                            "opinion_children": [
                                {
                                    "market_id": child["market_id"],
                                    "child_title": child["child_title"],
                                    "yes_token_id": child.get("yes_token_id"),
                                    "no_token_id": child.get("no_token_id"),
                                }
                                for child in unmatched_op
                            ],
                            "polymarket_children": [
                                {
                                    "condition_id": child["condition_id"],
                                    "question": child["question"],
                                    "slug": child["slug"],
                                    "yes_token_id": child["yes_token_id"],
                                    "no_token_id": child["no_token_id"],
                                }
                                for child in unmatched_pm
                            ],
                        }
                    )

                time.sleep(1)

        if unmatched_groups:
            self._save_unmatched_groups(unmatched_groups)

        self.market_matches = self.market_matches+matches
        print(f"\nâœ… å…±åŒ¹é…åˆ° {len(matches)} ä¸ªå¸‚åœºå¯¹")
        if unmatched_groups:
            print("âš ï¸  éƒ¨åˆ†å¸‚åœºç»„å­˜åœ¨æœªåŒ¹é…é¡¹ï¼Œå·²ä¿å­˜åˆ° unmatched_markets.json")
        print()
        return matches

    def _fetch_polymarket_event_markets(self, parent_title: str) -> List[Dict]:
        """è·å–æŒ‡å®šäº‹ä»¶ä¸‹çš„ Polymarket å­å¸‚åœº"""
        try:
            response = requests.get(
                f"{self.gamma_api}/public-search",
                params={"q": parent_title},
                timeout=10,
            )
            response.raise_for_status()
            results = response.json()

            events = results.get("events", [])
            if not events:
                return []

            first_event = events[0]
            event_description = first_event.get("description", "")
            markets = first_event.get("markets", [])
            if not markets:
                return []

            pm_children = []
            for market in markets:
                entry = self._extract_market_entry(market, event_description)
                if entry:
                    pm_children.append(entry)

            return pm_children
        except Exception as exc:  # pragma: no cover - ä»…è®°å½•æ—¥å¿—
            print(f"  âœ— è·å– Polymarket äº‹ä»¶å¤±è´¥: {exc}")
            return []

    def _match_child_markets(
        self,
        op_children: List[Dict],
        pm_children: List[Dict],
        parent_title: str,
    ) -> Tuple[List[MarketMatch], List[Dict], List[Dict]]:
        """æ ¹æ®å­å¸‚åœºæ ‡é¢˜åšåŒ…å«åŒ¹é…"""
        matches: List[MarketMatch] = []
        unmatched_op: List[Dict] = []
        unmatched_pm: List[Dict] = list(pm_children)

        for op_child in op_children:
            child_title = op_child["child_title"]
            child_title_lower = child_title.lower().strip()

            found_match = None
            for pm_child in unmatched_pm:
                pm_question = pm_child["question"].lower().strip()
                if child_title_lower in pm_question or pm_question in child_title_lower:
                    found_match = pm_child
                    break

            if found_match:
                combined_title = f"{parent_title} - {child_title}"
                matches.append(
                    MarketMatch(
                        question=combined_title,
                        opinion_market_id=op_child["market_id"],
                        opinion_yes_token=op_child.get("yes_token_id", "") or "",
                        opinion_no_token=op_child.get("no_token_id", "") or "",
                        cutoff_at=op_child.get("cutoff_at"),
                        polymarket_condition_id=found_match["condition_id"],
                        polymarket_yes_token=found_match["yes_token_id"],
                        polymarket_no_token=found_match["no_token_id"],
                        polymarket_slug=found_match["slug"],
                        similarity_score=1.0,
                        op_rules=op_child.get("rules", ""),
                        poly_rules=found_match.get("description", ""),
                        polymarket_neg_risk=found_match.get("neg_risk", False),  # æ·»åŠ  neg_risk
                    )
                )
                unmatched_pm.remove(found_match)
                print(f"    âœ“ {child_title[:40]} â†’ {found_match['question'][:40]}")
            else:
                unmatched_op.append(op_child)
                print(f"    âœ— {child_title[:40]} (æœªåŒ¹é…)")

        return matches, unmatched_op, unmatched_pm

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """ç®€å•çš„ Jaccard ç›¸ä¼¼åº¦"""
        words1 = set(text1.split())
        words2 = set(text2.split())

        if not words1 and not words2:
            return 0.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        if not union:
            return 0.0

        return len(intersection) / len(union)

    # ==================== ä¿å­˜ç»“æœ ====================

    def _save_unmatched_groups(self, unmatched_groups: List[Dict]):
        """ä¿å­˜æœªåŒ¹é…å¸‚åœºç»„åˆ° unmatched_markets.json"""
        filename = self.unmatched_output_file
        with open(filename, "w", encoding="utf-8") as file:
            json.dump(unmatched_groups, file, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ æœªåŒ¹é…å¸‚åœºç»„å·²ä¿å­˜åˆ°: {filename}")

    def save_market_matches(self, filename: str = "market_matches.json"):
        """ä¿å­˜åŒ¹é…ç»“æœ"""
        data = [asdict(match) for match in self.market_matches]
        with open(filename, "w", encoding="utf-8") as file:
            json.dump(data, file, indent=2, ensure_ascii=False)
        print(f"âœ… å¸‚åœºåŒ¹é…ç»“æœå·²ä¿å­˜åˆ°: {filename}")


def load_markets_from_file(path: str) -> List[Dict]:
    """ä» JSON æ–‡ä»¶åŠ è½½å¸‚åœºåˆ—è¡¨"""
    file_path = Path(path)
    if not file_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")

    with file_path.open("r", encoding="utf-8") as file:
        data = json.load(file)

    if not isinstance(data, list):
        raise ValueError(f"æ–‡ä»¶ {file_path} çš„å†…å®¹ä¸æ˜¯åˆ—è¡¨")

    return data


def main() -> None:
    parser = argparse.ArgumentParser(description="è·¨å¹³å°å¸‚åœºåŒ¹é…å·¥å…·")
    parser.add_argument(
        "--topic-type",
        default="BINARY,CATEGORICAL",
        help="æŒ‡å®šè¦å¤„ç†çš„ Opinion å¸‚åœºç±»å‹ï¼Œå¯ç”¨é€—å·åˆ†éš” (ä¾‹å¦‚: BINARY,CATEGORICAL)",
    )
    parser.add_argument(
        "--output",
        default="market_matches_1205.json",
        help="ä¿å­˜åŒ¹é…ç»“æœçš„æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--unmatched-file",
        default="unmatched_markets.json",
        help="ä¿å­˜æœªåŒ¹é…å¸‚åœºç»„çš„æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--gamma-api",
        default="https://gamma-api.polymarket.com",
        help="è‡ªå®šä¹‰ Gamma API æ ¹è·¯å¾„",
    )
    args = parser.parse_args()

    scanner = CrossPlatformArbitrage(
        gamma_api=args.gamma_api,
        unmatched_output_file=args.unmatched_file,
    )

    topic_values = [value.strip() for value in args.topic_type.split(",") if value.strip()]

    for topic_value in topic_values:
        if topic_value.upper() not in {"BINARY", "CATEGORICAL"}:
            print(f"âŒ æ— æ•ˆçš„ topic_type: {topic_value}ã€‚ä»…æ”¯æŒ BINARY/CATEGORICALã€‚")
            sys.exit(1)
        try:
            opinion_markets = scanner.fetch_opinion_markets(600, topic_type=TopicType[topic_value.upper()])
        except Exception as exc:
            print(f"âŒ æ— æ³•åŠ è½½ Opinion å¸‚åœºæ–‡ä»¶: {exc}")
            sys.exit(1)

        scanner.opinion_markets = opinion_markets

        scanner.match_markets_by_search(topic_types=topic_values)

    scanner.save_market_matches(args.output)


if __name__ == "__main__":
    main()
